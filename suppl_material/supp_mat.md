## Table 1
Song selection with emotion and quadrant information for annotation analysis, including synonyms for query and lyrics language. * refers to the annotation in the 4Q emotion data set. ** refers to audio features retrieved from the Spotify API: beats per minute (BPM), energy (A), and valence (V). Values in *italics* show disagreement between the original annotations and Spotify audio features. We normalized the range for energy and valence to [-1,1] for comparison purposes. <br>
![Table 1][table1]

## Table 2
Results from Median Test and Kruskal-Wallis H Test: German (N=374), English (N=572), Mandarin (N=594), Spanish (N=1232). Significance at p &lt;0\.01 is depicted with **. <br>
![Table 2][table2]

## Table 3
Music Sophistication Index results for participants in each language. We report mean and standard deviation for each factor. First column reports the possible ranges of each score and population means from the original study. <br>
![Table 3][table3]

## Table 4
Cross-correlations between ratings of emotion for music with lyrics in English. Significance at p&lt;0\.05 and p &lt;0\.01 are depicted with * and **, respectively. <br>
![Table 4][table4]

## Figure 1
Example of web survey in English for the annotation of an excerpt made in Psytoolkit: we used synonyms for each emotion and a 5-point Likert response format. <br>
![Figure 1][fig1]

## Figure 2
Resulting distribution of centroids after factor analysis with CATPCA. Emotions belonging to quadrants result with closer centroids: Q1 (joy, surprise, power), Q2 (anger, fear, tension), Q3 (sadness, bitterness), and Q4 (peace, tenderness, transcendence). <br>
![Figure 2][fig2]

## Figure 3
Example of clustering in 3D with *MDS* with *positive emotion perception score*. Top left: resulting embeddings, top right: kept embeddings in color and removed in grey, bottom left: remaining embeddings, bottom right: resulting clusters using K-Means. <br>
![Figure 3][fig3]

## Figure 4
Example of clustering in 2D with *MDS* with *positive familiarity*. Top left: resulting embeddings, top right: kept embeddings in color and removed in grey, bottom left: remaining embeddings, bottom right: resulting clusters using K-Means. <br>
![Figure 4][fig4]


## Figure 5
Example of clustering in 2D with *UMAP* with *positive lyrics comprehension*. Top left: resulting embeddings, top right: kept embeddings in color and removed in grey, bottom left: remaining embeddings, bottom right: resulting clusters using K-Means. <br>
![Figure 5][fig5]

[table1]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/table1.png "Table 1"
[table2]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/table2.png "Table 2"
[table3]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/table3.png "Table 3"
[table4]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/table4.png "Table 4"
[fig1]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/fig1.png "Figure 1"
[fig2]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/fig2.png "Figure 2"
[fig3]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/fig3.png "Figure 3"
[fig4]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/fig4.png "Figure 4"
[fig5]: https://github.com/juansgomez87/agreement-emotion/blob/master/suppl_material/img/fig5.png "Figure 5"

